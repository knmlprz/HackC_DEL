{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Ustawienia\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "LEARNING_RATE = 0.001\n",
    "MEMORY_SIZE = 10000\n",
    "NUM_EPISODES = 500\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 5])"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame 100x 4 list corStart corsStop timestart timeStop\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=['corStart', 'corsStop', 'timestart', 'timeStop'])\n",
    "\n",
    "#add new column sum\n",
    "df['sum'] = df['timestart'] + df['timeStop']\n",
    "#convert to tensor\n",
    "df = torch.tensor(df.values).float()\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SUMO_RUN():  # add action\n",
    "    df = pd.DataFrame(\n",
    "        np.random.randint(0, 100, size=(100, 4)),\n",
    "        columns=[\"corStart\", \"corsStop\", \"timestart\", \"timeStop\"],\n",
    "    )\n",
    "\n",
    "    df[\"sum\"] = df[\"timestart\"] + df[\"timeStop\"]\n",
    "\n",
    "    tensor = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_by_time_intervals(df, time_col_name, sum_col_name, interval):\n",
    "    # Oblicz maksymalną wartość w kolumnie czasowej, aby określić, ile przedziałów potrzebujemy\n",
    "    max_time = df[time_col_name].max()\n",
    "    # Obliczamy liczbę przedziałów na podstawie maksymalnego czasu i długości przedziału\n",
    "    num_intervals = int(np.ceil(max_time / interval))\n",
    "    \n",
    "    # Tworzymy wektor zer o długości liczby przedziałów do przechowywania sum\n",
    "    vec_of_sum = np.zeros(num_intervals)\n",
    "    \n",
    "    # Iterujemy przez każdy wiersz DataFrame\n",
    "    for i in range(len(df)):\n",
    "                # Oblicz indeks przedziału dla aktualnego wiersza\n",
    "        interval_index = int(df[time_col_name][i] // interval)\n",
    "        # Upewnij się, że nie przekraczamy zakresu wektora\n",
    "        if interval_index < num_intervals:\n",
    "            # Dodaj wartość z kolumny sum do odpowiedniego przedziału\n",
    "            vec_of_sum[interval_index] += df[sum_col_name][i]\n",
    "            \n",
    "    return vec_of_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr  7 05:09:00 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     On   | 00000000:01:00.0 Off |                  Off |\n",
      "| 33%   32C    P8    16W / 260W |   1657MiB / 49152MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    562042      C   ...nvs/TRAFFIC311/bin/python      832MiB |\n",
      "|    0   N/A  N/A    562176      C   ...nvs/TRAFFIC311/bin/python      822MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = torch.zeros(len(state))\n",
    "actions[0] = 1\n",
    "actions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_models(model, state):\n",
    "    add_tim = [-30, -25, -20, -15, -10, -5, 0, 5, 10, 15, 25, 20, 30]\n",
    "    add_tim = torch.tensor(add_tim)\n",
    "    actions = torch.zeros(len(state))\n",
    "    for i in range(0, len(state)):\n",
    "        value, index = model(state[i]).max(dim=0)\n",
    "\n",
    "        x = add_tim[index]\n",
    "        actions[i] = state[i][2] + add_tim[index]\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "def SUMO(state, action):  #TODOOOOOOOOOOOOO\n",
    "    # integral_t0=np.trapz(sum_by_time_intervals(state,'timeStop', 'sum', 10), dx=1)\n",
    "    new_state =SUMO_RUN().to(DEVICE)\n",
    "    # integral_t1=np.trapz(sum_by_time_intervals(new_state,'timeStop', 'sum', 10), dx=1)\n",
    "\n",
    "    # if integral_t0>integral_t1:\n",
    "    #     reward = 1\n",
    "    # else:\n",
    "    #     reward = -1\n",
    "    reward =1 \n",
    "\n",
    "    return new_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_in = torch.zeros(5)\n",
    "tensor_out = torch.zeros(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.flatten()\n",
    "policy_net = DQN(len(tensor_in), len(tensor_out)).to(DEVICE)\n",
    "target_net = DQN(len(tensor_in), len(tensor_out)).to(DEVICE)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "memory = ReplayMemory(MEMORY_SIZE)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "# def select_action(state):\n",
    "#     state = state.flatten()\n",
    "#     global steps_done\n",
    "#     sample = random.random()\n",
    "#     eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "#         np.exp(-1. * steps_done / EPS_DECAY)\n",
    "#     steps_done += 1\n",
    "#     if sample > eps_threshold:\n",
    "#         with torch.no_grad():\n",
    "#             print(state.shape)\n",
    "#             value, index = policy_net(state).max(dim=0)\n",
    "#             return index\n",
    "\n",
    "#     else:\n",
    "#         return torch.tensor([[random.randrange(2)]], device=DEVICE, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(\n",
    "        tuple(map(lambda s: s is not None, batch.next_state)),\n",
    "        device=DEVICE,\n",
    "        dtype=torch.bool,\n",
    "    )\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "\n",
    "\n",
    "    state_batch = torch.cat(batch.state).to(DEVICE)\n",
    "    action_batch = torch.cat(batch.action).to(DEVICE)\n",
    "    reward_batch = torch.cat(batch.reward).to(DEVICE)\n",
    "\n",
    "    state_action_values = for_models(policy_net.to(DEVICE), state_batch.to(DEVICE)).to(DEVICE).gather(1, action_batch.to(DEVICE)).to(DEVICE)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=DEVICE)\n",
    "    next_state_values[non_final_mask.to(DEVICE)] = (\n",
    "        for_models(target_net.to(DEVICE), non_final_next_states.to(DEVICE)).max(1)[0].detach().to(DEVICE)\n",
    "    )\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    loss = nn.SmoothL1Loss()(\n",
    "        state_action_values, expected_state_action_values.unsqueeze(1)\n",
    "    )\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([ 78., 123.,  81.,  ...,  43.,  91.,  29.], device='cuda:0')\n",
      "torch.Size([6400])\n",
      "6400\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[526], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# print(state.shape, action.shape, next_state.shape, reward)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m---> 18\u001b[0m     \u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i_episode \u001b[38;5;241m%\u001b[39m TARGET_UPDATE \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     23\u001b[0m     target_net\u001b[38;5;241m.\u001b[39mload_state_dict(policy_net\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "Cell \u001b[0;32mIn[525], line 22\u001b[0m, in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(for_models(policy_net\u001b[38;5;241m.\u001b[39mto(DEVICE), state_batch\u001b[38;5;241m.\u001b[39mto(DEVICE))\u001b[38;5;241m.\u001b[39mto(DEVICE)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(state_batch))    \n\u001b[0;32m---> 22\u001b[0m state_action_values \u001b[38;5;241m=\u001b[39m \u001b[43mfor_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     24\u001b[0m next_state_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(BATCH_SIZE, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m     25\u001b[0m next_state_values[non_final_mask\u001b[38;5;241m.\u001b[39mto(DEVICE)] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     26\u001b[0m     for_models(target_net\u001b[38;5;241m.\u001b[39mto(DEVICE), non_final_next_states\u001b[38;5;241m.\u001b[39mto(DEVICE))\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     27\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "i =0 \n",
    "for i_episode in range(NUM_EPISODES):\n",
    "    state = SUMO_RUN().to(DEVICE)\n",
    "    print(i)\n",
    "    i+=1\n",
    "    for t in count():\n",
    "        action = for_models(policy_net, state)\n",
    "        next_state, reward = SUMO(state, action)\n",
    "        \n",
    "\n",
    "        reward = torch.tensor([reward], device=DEVICE)\n",
    "        \n",
    "        memory.push(state, action, next_state, reward)\n",
    "        # print(state.shape, action.shape, next_state.shape, reward)\n",
    "        \n",
    "        state = next_state\n",
    "        optimize_model()\n",
    "        \n",
    "        \n",
    "            \n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Training complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
